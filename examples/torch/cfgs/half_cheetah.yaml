defaults:
  - train_config
  - override hydra/launcher: slurm
  - _self_

_target_: "__main__.main"
env_name: "HalfCheetahV2"
seed: 42
wm_embedding_hidden_size: 32
n_heads: 16
d_model: 128
layers: 4
wm_size: 5
em_size: 5
dim_ff: 512
meta_batch_size: 20
episode_per_task: 2
discount: 0.9
gae_lambda: 0.8
lr_clip_range: 0.2
policy_lr: 3e-05
vf_lr: 3e-05
minibatch_size: 256
max_opt_epochs: 10
policy_ent_coeff: 0.0
entropy_method: "regularized"
architecture: "Encoder"
policy_head_input: "latest_memory"
init_std: 0.5
# remove_ln: true # setting true breaks with is_causal
tfixup: true
learn_std: true
pre_lnorm: true
init_params: true
use_softplus_entropy: true
policy_lr_schedule: "decay"
vf_lr_schedule: "decay"
# share_network: true
decay_epoch_init: 100
decay_epoch_end: 3700
min_lr_factor: 0.0001
policy_head_type: "Default"


wandb_group: "TrMRL"
wandb_project_name: "adaptive-context-rl"
use_wandb: True
wandb_run_name: seed=${seed}-${now:%Y-%m-%d_%H-%M-%S}
wandb_tags:
  - "TrMRL"

hydra:
  run:
    dir: output/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: true
  sweep:
    dir: ${hydra.run.dir}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO # DEBUG
